# ğŸš€ CASIMAGE â€“ Pipeline ETL Professionnel

**Auteur :** Data Engineering Team (Kacem Chayma â€“ Nechi Zeinabâ€“ Hammami Emir)

---

## ğŸ“Œ 1. Objectif du pipeline ETL

Ce pipeline traite les cas radiologiques CASIMAGE depuis leur format brut (ZIP/XML) jusquâ€™Ã  un **Data Warehouse en schÃ©ma en Ã©toile** prÃªt pour la BI, le reporting et la data science.

Il rÃ©alise :

* **Extract** : Extraction ZIP â†’ Parsing XML â†’ Transformation structurÃ©e
* **Transform** : Nettoyage basique + nettoyage intelligent (Ã¢ge, sexe, mÃ©tadonnÃ©es) + enrichissement + mapping IA
* **Load** : Export CSV/Parquet + chargement Data Warehouse (SQLite/MySQL possible)

---

## ğŸ¯ 2. Architecture gÃ©nÃ©rale

```
/data
    â””â”€â”€ *.zip  (CASIMAGE raw)
/src
    â”œâ”€â”€ xml_utils.py          â†’ unzip & parsing
    â”œâ”€â”€ transform_utils.py    â†’ flatten, text cleaning
    â”œâ”€â”€ enhanced_cleaning.py  â†’ Age/Sex/Metadata intelligence
    â”œâ”€â”€ clean_data.py         â†’ EDA cleaning
    â”œâ”€â”€ dw_model.py           â†’ Star Schema builder
    â”œâ”€â”€ main.py               â†’ Full ETL pipeline
    â””â”€â”€ run_pipeline.py       â†’ CLI runner
/output
    â”œâ”€â”€ casimage_ai.csv
    â”œâ”€â”€ casimage_ai.parquet
    â”œâ”€â”€ mapping_ai.json
    â””â”€â”€ dw.sqlite (ou MySQL)
```

---

## ğŸ“¥ 3. Ã‰tape EXTRACT (E)

### âœ” 3.1. Extraction ZIP

* DÃ©tection automatique du fichier ZIP dans `/data`
* Extraction dans `/extract`
* RÃ©cupÃ©ration de tous les fichiers `*.xml`

### âœ” 3.2. Parsing XML â†’ Dict Python

Utilisation de :

```python
xmltodict.parse()
```

Gestion :

* encodage iso-8859-1
* nettoyage caractÃ¨res illÃ©gaux
* aplatissage structure XML â†’ lignes tabulaires

### âœ” 3.3. Extraction du QCM & structures imbriquÃ©es

`flatten_qcm()` gÃ©nÃ¨re un dictionnaire structurÃ© contenant :

* items
* questions/rÃ©ponses
* annotations

---

## ğŸ”„ 4. Ã‰tape TRANSFORM (T)

Transformation en **deux couches** :

### ğŸ§¹ 4.1. Nettoyage basique

* suppression doublons
* trim des chaÃ®nes
* valeurs vides â†’ `None`
* homogÃ©nÃ©isation texte

### ğŸ§  4.2. Nettoyage avancÃ© intelligent

Module : `enhanced_cleaning.py`

FonctionnalitÃ©s clÃ©s :

* **DÃ©tection automatique de lâ€™Ã¢ge** via :

  * champ Age
  * texte libre "Homme de 45 ans" (regex)
  * Birthdate + Date
* **DÃ©tection du sexe (M/F)** via :

  * mots clÃ©s explicites
  * anatomie spÃ©cifique (prostate â†’ M, utÃ©rus â†’ F)
* **Nettoyage mÃ©tadonnÃ©es O*** (colonnes techniques inutiles)
* **Suppression lignes sans Ã¢ge**

### ğŸ›  4.3. Conversion de types + enrichissements EDA

Module : `clean_data.py`

* Age â†’ numÃ©rique
* Date / Birthdate â†’ datetime
* Ajout : `Year`, `AgeGroup`

### ğŸ¤– 4.4. Mapping IA

Module : `ai_mapper.py`
GÃ©nÃ¨re un mapping JSON basÃ© sur la structure XML analysÃ©e.

---

## ğŸ› 5. Ã‰tape LOAD (L)

### âœ” 5.1. Export fichiers analytiques

Formats produits dans `/output` :

* `casimage_ai.csv`
* `casimage_ai.parquet`
* `mapping_ai.json`

### â­ 5.2. Chargement Data Warehouse (Star Schema)

Module : `dw_model.py`

SchÃ©ma en Ã©toile construit automatiquement :

### ğŸ“‚ DIM_PATIENT

* patient_id
* age
* sex

### ğŸ“‚ DIM_EXAM

* exam_id
* date
* year
* anatomy
* chapter
* hospital
* department

### ğŸ“‚ DIM_PATHOLOGY

* pathology_id
* diagnosis_clean

### ğŸ“‚ FACT_CASE

* fact_id
* patient_id (FK)
* exam_id (FK)
* pathology_id (FK)
* keywords
* description
* clinicalPresentation

Star schema chargÃ© par dÃ©faut dans **SQLite** mais compatible MySQL.

---

## ğŸš€ 6. Execution totale

### CLI simple :

```bash
python src/main.py
```

Ou version orchestrÃ©e :

```bash
python src/run_pipeline.py
```

---

## ğŸ“Š 7. RÃ©sultat final

Ã€ la fin du pipeline :

* DW complet
* Fichiers propres analytiques
* Star Schema consultable depuis Power BI, Tableau, Metabase, MySQL Workbench

---

## ğŸ§± 8. Extension : connexion MySQL

Remplacement du loader SQLite dans `dw_model.py` par un loader MySQL via `mysql.connector`.
Permet intÃ©gration avec **XAMPP / phpMyAdmin**.

---

## ğŸ 9. Conclusion

Ce pipeline fournit :

* un traitement robuste
* un Data Warehouse structurÃ©
* un code modulaire & maintenable
* une architecture Data Engineer professionnelle

Ce fichier peut Ãªtre placÃ© dans :

```
src/docs/etl_pipeline.md
```
